{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9994495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf721d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_With_VGG_Weights(X_size,Y_size,Num_channels,Num_classes):\n",
    "    \n",
    "    # Lets retrieve the VGG Graph and modify the graph and reuse the weights\n",
    "    vgg16 = tf.keras.applications.vgg16.VGG16(weights = \"imagenet\")\n",
    "    \n",
    "    # Getting the Blocks of VGG\n",
    "    block1_conv1 = vgg16.get_layer(\"block1_conv1\")\n",
    "    block1_conv2 = vgg16.get_layer(\"block1_conv2\")\n",
    "    block1_pool = vgg16.get_layer(\"block1_pool\")\n",
    "    \n",
    "    block2_conv1 = vgg16.get_layer(\"block2_conv1\")\n",
    "    block2_conv2 = vgg16.get_layer(\"block2_conv2\")\n",
    "    block2_pool = vgg16.get_layer(\"block2_pool\")\n",
    "    \n",
    "    block3_conv1 = vgg16.get_layer('block3_conv1')\n",
    "    block3_conv2 = vgg16.get_layer('block3_conv2')\n",
    "    block3_conv3 = vgg16.get_layer('block3_conv3')\n",
    "    block3_pool = vgg16.get_layer('block3_pool')\n",
    "    \n",
    "    block4_conv1 = vgg16.get_layer('block4_conv1')\n",
    "    block4_conv2 = vgg16.get_layer('block4_conv2')\n",
    "    block4_conv3 = vgg16.get_layer('block4_conv3')\n",
    "    block4_pool = vgg16.get_layer('block4_pool')\n",
    "\n",
    "    block5_conv1 = vgg16.get_layer('block5_conv1')\n",
    "    block5_conv2 = vgg16.get_layer('block5_conv2')\n",
    "    block5_conv3 = vgg16.get_layer('block5_conv3')\n",
    "    block5_pool = vgg16.get_layer('block5_pool')\n",
    "    \n",
    "    FC1 = vgg16.get_layer('fc1')\n",
    "    FC2 = vgg16.get_layer('fc2')\n",
    "    \n",
    "    # Converting the FC1 and FC2 to Convolutional Layer\n",
    "    FC_1 = Convolutionalize_me(FC1,(7, 7, 512, 4096))  # Filter = 7x7, #filters = 512, Output Filter = 4096\n",
    "    FC_2 = Convolutionalize_me(FC2,(1, 1, 4096, 4096))\n",
    "    \n",
    "    # Using these above weights to Recreate the Graph\n",
    "    input_ = tf.keras.layers.Input(shape=(X_size,Y_size,Num_channels),name = \"Input_Layer\")\n",
    "    # Adding some zero Padding symmetrically\n",
    "    img = tf.keras.layers.ZeroPadding2D(100)(input_)\n",
    "    \n",
    "    # Block 1\n",
    "    img = block1_conv1(img)\n",
    "    img = block1_conv2(img)\n",
    "    img = block1_pool(img)\n",
    "    #Block 2\n",
    "    img = block2_conv1(img)\n",
    "    img = block2_conv2(img)\n",
    "    img = block2_pool(img)\n",
    "    #Block 3\n",
    "    img = block3_conv1(img)\n",
    "    img = block3_conv2(img)\n",
    "    img = block3_conv3(img)\n",
    "    img = block3_pool(img)\n",
    "    pool3 = img\n",
    "    #Block 4\n",
    "    img = block4_conv1(img)\n",
    "    img = block4_conv2(img)\n",
    "    img = block4_conv3(img)\n",
    "    img = block4_pool(img)\n",
    "    pool4 = img\n",
    "    #Block 5\n",
    "    img = block5_conv1(img)\n",
    "    img = block5_conv2(img)\n",
    "    img = block5_conv3(img)\n",
    "    img = block5_pool(img)\n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    img = FC_1(img)\n",
    "    img = tf.keras.layers.Dropout(rate = 0.5)(img)\n",
    "    \n",
    "    img = FC_2(img)\n",
    "    img = tf.keras.layers.Dropout(rate = 0.5)(img)\n",
    "    \n",
    "    Out = tf.keras.layers.Conv2D(Num_classes,1,padding = \"valid\",activation = \"relu\",use_bias = True,name = \"Encoder_Output\")(img)\n",
    "    \n",
    "    return input_,pool3,pool4,Out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367dc3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolutionalize_me(fc,Output_dim):\n",
    "    W,B = fc.get_weights()\n",
    "    W_Reshaped = W.reshape(Output_dim)\n",
    "    \n",
    "    conv_layer = tf.keras.layers.Conv2D(Output_dim[-1],(Output_dim[0],Output_dim[1]),padding = \"valid\",activation = \"relu\",weights = [W_Reshaped,B])\n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab7fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Initialized_Net(X_size,Y_size,Num_channels,Num_classes):\n",
    "    input_ = tf.keras.layers.Input(shape=(X_size, Y_size, Num_channels), name='input_image')\n",
    "\n",
    "    img = tf.keras.layers.ZeroPadding2D(padding=100)(input_)\n",
    "\n",
    " \n",
    "    img = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', use_bias=True, name='block1_conv1')(img)\n",
    "    img = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', use_bias=True, name='block1_conv2')(img)\n",
    "    img = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', name='block1_pool')(img)\n",
    "    \n",
    "\n",
    "    img = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', use_bias=True, name='block2_conv1')(img)\n",
    "    img = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', use_bias=True, name='block2_conv2')(img)\n",
    "    img = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', name='block2_pool')(img)\n",
    "\n",
    "\n",
    "    img = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', use_bias=True, name='block3_conv1')(img)\n",
    "    img = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', use_bias=True, name='block3_conv2')(img)\n",
    "    img = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', use_bias=True, name='block3_conv3')(img)\n",
    "    img = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', name='block3_pool')(img)\n",
    "    pool_3 = img\n",
    "\n",
    "\n",
    "    img = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', use_bias=True, name='block4_conv1')(img)\n",
    "    img = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', use_bias=True, name='block4_conv2')(img)\n",
    "    img = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', use_bias=True, name='block4_conv3')(img)\n",
    "    img = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', name='block4_pool')(img)   \n",
    "    pool_4 = img\n",
    "\n",
    "\n",
    "\n",
    "    img = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', use_bias=True, name='block5_conv1')(img)\n",
    "    img = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', use_bias=True, name='block5_conv2')(img)\n",
    "    img = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', use_bias=True, name='block5_conv3')(img)\n",
    "    img = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid', name='block5_pool')(img)\n",
    "    \n",
    "\n",
    "    img = tf.keras.layers.Conv2D(4096, 7, padding='valid', activation='relu', use_bias=True, name='fc_1')(img)\n",
    "    img = tf.keras.layers.Dropout(0.5)(img)\n",
    "    \n",
    "\n",
    "    img = tf.keras.layers.Conv2D(4096, 1, padding='valid', activation='relu', use_bias=True, name='fc_2')(img)\n",
    "    img = tf.keras.layers.Dropout(0.5)(img)\n",
    "\n",
    "    Out_ = tf.keras.layers.Conv2D(Num_classes, 1, padding='valid', activation='relu', use_bias=True, name='encoder_graph')(img)\n",
    "    \n",
    "\n",
    "    \n",
    "    return input_, pool_3, pool_4, Out_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e170b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
