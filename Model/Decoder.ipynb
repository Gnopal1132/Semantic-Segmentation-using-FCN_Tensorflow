{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739d68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66da488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoder_8x(Encoder_out,pool3,pool4,num_class):\n",
    "    # Lets Deconvolutionalize at 16x\n",
    "    score = tf.keras.layers.Conv2DTranspose(num_class,4,strides = 2,padding = \"valid\")(Encoder_out)\n",
    "    pool4_out = tf.keras.layers.Conv2D(num_class,1,padding = \"valid\",use_bias = True)(pool4)\n",
    "    pool4_resize = tf.keras.layers.Cropping2D(cropping = 5)(pool4_out)\n",
    "    score_16x = tf.keras.layers.Add()([score,pool4_resize])\n",
    "    \n",
    "    # Deconvolutionalize at 8x\n",
    "    score = tf.keras.layers.Conv2DTranspose(num_class,4,strides = 2,padding = \"valid\")(score_16x)\n",
    "    pool3_out = tf.keras.layers.Conv2D(num_class,1,padding = \"valid\",use_bias = True)(pool3)\n",
    "    score_pad = tf.keras.layers.ZeroPadding2D(padding = ((1,0),(1,0)))(score)\n",
    "    pool3_resize = tf.keras.layers.Cropping2D(cropping = 9)(pool3_out)\n",
    "    score_8x = tf.keras.layers.Add()([score_pad,pool3_resize])\n",
    "    \n",
    "    # Resize to image Shape\n",
    "    Upsample = tf.keras.layers.Conv2DTranspose(num_class,16,strides = 8,padding = \"same\")(score_8x)\n",
    "    Upsample = tf.keras.layers.Cropping2D(cropping = 28)(Upsample)\n",
    "    \n",
    "    Out = tf.keras.layers.Activation(\"softmax\")(Upsample)\n",
    "    \n",
    "    return Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fa106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoder_16x(Encoder_out,pool4,num_class):\n",
    "    #Lets Deconvolutionalize at 16x\n",
    "    score = tf.keras.layers.Conv2DTranspose(num_class,4,strides = 2,padding = \"valid\")(Encoder_out)\n",
    "    pool4_out = tf.keras.layers.Conv2D(num_class,1,padding = \"valid\",use_bias = True)(pool4)\n",
    "    pool4_resize = tf.keras.layers.Cropping2D(cropping = 6)(pool4_out)\n",
    "    score_16x = tf.keras.layers.Add()([score,pool4_resize])\n",
    "    \n",
    "    # Resize to image Shape\n",
    "    Upsample = tf.keras.layers.Conv2DTranspose(num_class,32,strides = 16,padding = \"same\")(score_16x)\n",
    "    \n",
    "    Out = tf.keras.layers.Activation(\"softmax\")(Upsample)\n",
    "    \n",
    "    return Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75555474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoder_32x(Encoder_out,num_class):\n",
    "    # Resize to image Shape\n",
    "    Upsample = tf.keras.layers.Conv2DTranspose(num_class,64,strides = 32,padding = \"same\")(Encoder_out)\n",
    "    \n",
    "    Out = tf.keras.layers.Activation(\"softmax\")(Upsample)\n",
    "    \n",
    "    return Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1d317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
