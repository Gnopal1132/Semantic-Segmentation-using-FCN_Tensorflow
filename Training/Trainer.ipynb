{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "128d6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.path.abspath(r\"E:\\Study Material\\Python_Machine_AI\\Deep Learning_Lessons\\Praktisch\\Tensorflow\\Projects\\Semantic Segmentation FCN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd68362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Loss_Function.Custom_Loss_Function import Categorical_Cross_Entropy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9614770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "class OneCycleSchedule(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,iterations,max_rate,start_rate = None,last_iterations = None,last_rate = None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or max_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self,I1,I2,R1,R2):\n",
    "        return ((R2 - R1)*(self.iteration - I1)) / (I2-I1+R1)\n",
    "    def on_batch_begin(self,batch,logs):\n",
    "        if self.iteration < self.half_iteration:     # lINEAR RATE INCREASE\n",
    "            rate = self._interpolate(0,self.half_iteration,self.start_rate,self.max_rate)\n",
    "        elif self.iteration < 2*self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration,2*self.half_iteration,self.max_rate,self.start_rate)\n",
    "        else:  # Last few Iterations\n",
    "            rate = self._interpolate(2*self.half_iteration,self.last_iterations,self.start_rate,self.last_rate)\n",
    "            rate = max(rate,self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5995c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_id(path):\n",
    "    import time\n",
    "    fpath = os.path.join(path,\"My_logs\")\n",
    "    id_ = time.strftime(\"run_%Y_%m_%D_%H_%M_%S\")\n",
    "    return os.path.join(fpath,id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b751c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_FCN:\n",
    "    def __init__(self,config,model,Train_Generator,Val_Generator,Train_Size):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.Train_Generator = Train_Generator\n",
    "        self.Val_Generator = Val_Generator\n",
    "        self.epoch = self.config[\"train\"][\"epoch\"]\n",
    "        self.graph_path = self.config[\"Network\"][\"graph_path\"]\n",
    "        self.Train_Size = Train_Size\n",
    "        self.Out_Weight_path = self.config[\"train\"][\"Output\"][\"weight\"]\n",
    "        self.callbacks = self.Give_Callbacks()\n",
    "    \n",
    "    def Give_Callbacks(self):\n",
    "        Callbacks = []\n",
    "        if self.config[\"Callbacks\"][\"Earlystop\"][\"Use_Early_Stop\"]:\n",
    "            earlystop = tf.keras.callbacks.EarlyStopping(patience=self.config[\"Callbacks\"][\"Earlystop\"][\"patience\"],\n",
    "                                                        monitor=self.config[\"Callbacks\"][\"Earlystop\"][\"monitor\"],mode='auto')\n",
    "            Callbacks.append(earlystop)\n",
    "            \n",
    "        if self.config[\"Callbacks\"][\"Model_Checkpoint_Best\"][\"enabled\"]:  # Saving only best checkpoint\n",
    "            path = self.config[\"Callbacks\"][\"Model_Checkpoint_Best\"][\"out_file\"]\n",
    "            monitor = self.config[\"Callbacks\"][\"Model_Checkpoint_Best\"][\"monitor\"]\n",
    "            Best_Checkpoint = tf.keras.callbacks.ModelCheckpoint(path,monitor=monitor,save_best_only=True\n",
    "                                                                 ,save_weights_only=True,mode = \"min\",verbose = 1)\n",
    "            Callbacks.append(Best_Checkpoint)\n",
    "        \n",
    "        if self.config[\"Callbacks\"][\"Model_Checkpoint_last\"][\"enabled\"]:  # Saving only best checkpoint\n",
    "            path = self.config[\"Callbacks\"][\"Model_Checkpoint_last\"][\"Out_file\"]\n",
    "            Last_Checkpoint = tf.keras.callbacks.ModelCheckpoint(path,monitor=monitor,save_best_only=False\n",
    "                                                                 ,save_weights_only=True)\n",
    "            Callbacks.append(Last_Checkpoint)\n",
    "            \n",
    "        if self.config[\"Callbacks\"][\"Tensorboard\"][\"enabled\"]:\n",
    "            Event_Out = Get_id(self.config[\"Callbacks\"][\"Tensorboard\"][\"event_file\"])\n",
    "            Callbacks.append(tf.keras.callbacks.TensorBoard(log_dir = Event_Out))\n",
    "        \n",
    "        if self.config[\"Callbacks\"][\"OneCycle\"][\"enabled\"]:\n",
    "            rate = self.config[\"Callbacks\"][\"OneCycle\"][\"max_rate\"]\n",
    "            Iterations = self.Train_Size // self.config[\"train\"][\"batch_size\"] * self.epoch\n",
    "            Callbacks.append(OneCycleSchedule(iterations=Iterations,max_rate=rate))\n",
    "        return Callbacks\n",
    "    \n",
    "    def save_graph(self, model, graph_path):\n",
    "        model_json = model.to_json()\n",
    "        with open(graph_path, \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    \n",
    "    def Train(self):\n",
    "        \n",
    "        # Use Pretrained Weights\n",
    "        if self.config[\"train\"][\"weight_initialization\"][\"use_pretrained\"]:\n",
    "            read_from = self.config[\"train\"][\"weight_initialization\"][\"restore_from\"]\n",
    "            print(\"Restoring Weights From: \",read_from)\n",
    "            self.model.load_weights(read_from)\n",
    "        else:\n",
    "            print(\"Saving Weights\",self.graph_path)\n",
    "            self.save_graph(self.model,self.graph_path)\n",
    "            \n",
    "        # Compiling the model\n",
    "        opt = self.config[\"train\"][\"optimizer\"]\n",
    "        lr = self.config[\"train\"][\"learning_rate\"]\n",
    "      \n",
    "        if opt == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)   \n",
    "        elif opt == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False)\n",
    "        elif opt == 'rmsprop':\n",
    "            optimizer = tf.keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=None, decay=0.0)\n",
    "        elif opt == 'adagrad':\n",
    "            optimizer = tf.keras.optimizers.Adagrad(lr=lr, epsilon=None, decay=0.0)\n",
    "        elif opt == 'adadelta':\n",
    "            optimizer = tf.keras.optimizers.Adadelta(lr=lr, rho=0.95, epsilon=None, decay=0.0)\n",
    "        else:\n",
    "            raise Exception('Optimizer unknown')\n",
    "        \n",
    "        \n",
    "        self.model.compile(loss = Categorical_Cross_Entropy(),optimizer = optimizer)\n",
    "        \n",
    "        # Fitting the Model\n",
    "        Use_MultiProcessing = self.config[\"train\"][\"use_multiprocessing\"]\n",
    "        self.model.fit_generator(generator=self.Train_Generator, validation_data=self.Val_Generator, \n",
    "                                 epochs=self.epoch, verbose=1, max_queue_size=10, \n",
    "                                 workers=tf.data.AUTOTUNE, use_multiprocessing=Use_MultiProcessing, shuffle=False, \n",
    "                                 callbacks=self.callbacks)\n",
    "        #save weights\n",
    "        print(\"Saving weights in\", self.Out_Weight_path)\n",
    "        self.model.save(self.Out_Weight_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
